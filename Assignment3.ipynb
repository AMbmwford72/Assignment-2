{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f94a27-34ea-4a10-ae88-87c410a848e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Subset Selection Test RSS: [6478.277007674038, 4398.04268384516, 3860.938230651976, 3607.0915411657306, 3406.9094458522673]\n",
      "Forward Stepwise Selection Test RSS: [6478.277007674038, 4398.042683845158, 3860.938230651973, 3607.091541165726, 3406.9094458522527]\n",
      "Backward Stepwise Selection Test RSS: [3014.361198153569, 3013.5408061796443, 2988.8817999575567, 3150.5262991775944, 3333.6484843139674, 3437.634333492885, 3377.152670481532, 3325.513189105136, 3406.9094458522673, 3607.0915411657306, 3860.938230651976, 4398.04268384516, 6478.277007674038]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load Boston dataset\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=r\"\\s+\", skiprows=22, header=None)\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "target = raw_df.values[1::2, 2]\n",
    "\n",
    "# Convert data to DataFrame and assign X, y\n",
    "X = pd.DataFrame(data, columns=[\n",
    "    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', \n",
    "    'TAX', 'PTRATIO', 'B', 'LSTAT'\n",
    "])\n",
    "y = pd.Series(target, name='MEDV')\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "def get_best_subset(X, y, k):\n",
    "    \"\"\" Finds the best subset of k predictors based on training RSS. \"\"\"\n",
    "    best_model = None\n",
    "    best_rss = np.inf\n",
    "    for subset in itertools.combinations(X.columns, k):\n",
    "        X_subset = X[list(subset)]\n",
    "        X_subset = sm.add_constant(X_subset)  # add constant for intercept\n",
    "        model = sm.OLS(y, X_subset).fit()\n",
    "        rss = ((model.predict(X_subset) - y) ** 2).sum()\n",
    "        if rss < best_rss:\n",
    "            best_rss = rss\n",
    "            best_model = model\n",
    "    return best_model\n",
    "\n",
    "# Best subset selection\n",
    "best_subset_models = {}\n",
    "for k in range(1, 6):  # Limiting to models with up to 5 predictors\n",
    "    best_subset_models[k] = get_best_subset(X_train, y_train, k)\n",
    "\n",
    "# Forward Stepwise Selection\n",
    "def forward_stepwise(X, y, max_features):\n",
    "    remaining_predictors = list(X.columns)\n",
    "    selected_predictors = []\n",
    "    models = []\n",
    "    for _ in range(max_features):\n",
    "        best_rss = np.inf\n",
    "        best_predictor = None\n",
    "        for predictor in remaining_predictors:\n",
    "            model_predictors = selected_predictors + [predictor]\n",
    "            X_model = X[model_predictors]\n",
    "            X_model = sm.add_constant(X_model)\n",
    "            model = sm.OLS(y, X_model).fit()\n",
    "            rss = ((model.predict(X_model) - y) ** 2).sum()\n",
    "            if rss < best_rss:\n",
    "                best_rss = rss\n",
    "                best_predictor = predictor\n",
    "        selected_predictors.append(best_predictor)\n",
    "        remaining_predictors.remove(best_predictor)\n",
    "        models.append(sm.OLS(y, sm.add_constant(X[selected_predictors])).fit())\n",
    "    return models\n",
    "\n",
    "forward_stepwise_models = forward_stepwise(X_train, y_train, max_features=5)\n",
    "\n",
    "# Backward Stepwise Selection\n",
    "def backward_stepwise(X, y):\n",
    "    selected_predictors = list(X.columns)\n",
    "    models = [sm.OLS(y, sm.add_constant(X[selected_predictors])).fit()]\n",
    "    while len(selected_predictors) > 1:\n",
    "        best_rss = np.inf\n",
    "        worst_predictor = None\n",
    "        for predictor in selected_predictors:\n",
    "            model_predictors = [p for p in selected_predictors if p != predictor]\n",
    "            X_model = X[model_predictors]\n",
    "            X_model = sm.add_constant(X_model)\n",
    "            model = sm.OLS(y, X_model).fit()\n",
    "            rss = ((model.predict(X_model) - y) ** 2).sum()\n",
    "            if rss < best_rss:\n",
    "                best_rss = rss\n",
    "                worst_predictor = predictor\n",
    "        selected_predictors.remove(worst_predictor)\n",
    "        models.append(sm.OLS(y, sm.add_constant(X[selected_predictors])).fit())\n",
    "    return models\n",
    "\n",
    "backward_stepwise_models = backward_stepwise(X_train, y_train)\n",
    "\n",
    "# Testing RSS Comparison\n",
    "def calculate_test_rss(models, X_test, y_test):\n",
    "    rss_list = []\n",
    "    for model in models:\n",
    "        predictors = model.model.exog_names\n",
    "        X_test_subset = X_test[predictors[1:]]  # exclude constant term\n",
    "        X_test_subset = sm.add_constant(X_test_subset)\n",
    "        y_pred = model.predict(X_test_subset)\n",
    "        rss = ((y_pred - y_test) ** 2).sum()\n",
    "        rss_list.append(rss)\n",
    "    return rss_list\n",
    "\n",
    "# Calculate RSS for test data\n",
    "best_subset_rss = calculate_test_rss(best_subset_models.values(), X_test, y_test)\n",
    "forward_stepwise_rss = calculate_test_rss(forward_stepwise_models, X_test, y_test)\n",
    "backward_stepwise_rss = calculate_test_rss(backward_stepwise_models, X_test, y_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Best Subset Selection Test RSS:\", best_subset_rss)\n",
    "print(\"Forward Stepwise Selection Test RSS:\", forward_stepwise_rss)\n",
    "print(\"Backward Stepwise Selection Test RSS:\", backward_stepwise_rss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814257fc-6ff4-4345-9129-c0096b322185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    mpg   R-squared:                       0.606\n",
      "Model:                            OLS   Adj. R-squared:                  0.605\n",
      "Method:                 Least Squares   F-statistic:                     599.7\n",
      "Date:                Sat, 26 Oct 2024   Prob (F-statistic):           7.03e-81\n",
      "Time:                        23:00:48   Log-Likelihood:                -1178.7\n",
      "No. Observations:                 392   AIC:                             2361.\n",
      "Df Residuals:                     390   BIC:                             2369.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         39.9359      0.717     55.660      0.000      38.525      41.347\n",
      "horsepower    -0.1578      0.006    -24.489      0.000      -0.171      -0.145\n",
      "==============================================================================\n",
      "Omnibus:                       16.432   Durbin-Watson:                   0.920\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.305\n",
      "Skew:                           0.492   Prob(JB):                     0.000175\n",
      "Kurtosis:                       3.299   Cond. No.                         322.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "        mean  mean_ci_lower  mean_ci_upper  obs_ci_lower  obs_ci_upper\n",
      "0  24.467077      23.973079      24.961075     14.809396     34.124758\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the Auto dataset\n",
    "file_path = 'C:/Users/arman/Downloads/ALL+CSV+FILES+-+2nd+Edition+-+corrected/ALL CSV FILES - 2nd Edition/Auto.csv'\n",
    "auto_data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert horsepower to numeric, coerce errors to NaN, and drop rows with NaN values\n",
    "auto_data['horsepower'] = pd.to_numeric(auto_data['horsepower'], errors='coerce')\n",
    "auto_data.dropna(subset=['horsepower', 'mpg'], inplace=True)\n",
    "\n",
    "# Define predictor (X) and response (y)\n",
    "X = sm.add_constant(auto_data['horsepower'])  # Adding a constant for intercept\n",
    "y = auto_data['mpg']\n",
    "\n",
    "# Perform simple linear regression using sm.OLS\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(model.summary())\n",
    "\n",
    "# Calculate the predicted mpg for horsepower = 98\n",
    "horsepower_98 = pd.DataFrame({'const': 1, 'horsepower': [98]})\n",
    "predicted_mpg_98 = model.get_prediction(horsepower_98)\n",
    "\n",
    "# Get the confidence and prediction intervals at 95% confidence level\n",
    "prediction_summary_98 = predicted_mpg_98.summary_frame(alpha=0.05)\n",
    "print(prediction_summary_98[['mean', 'mean_ci_lower', 'mean_ci_upper', 'obs_ci_lower', 'obs_ci_upper']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b848624-8e97-4f2e-b7a0-45c14bda1f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE (Ridge Model): 0.17256617684408151\n",
      "RMSLE (PCR Model): 0.17457462367892795\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv('C:/Users/arman/Downloads/playground-series-s4e4/train.csv')\n",
    "test_data = pd.read_csv('C:/Users/arman/Downloads/playground-series-s4e4/test.csv')\n",
    "\n",
    "# Data Preparation\n",
    "# Drop duplicate columns in train and test data\n",
    "train_data = train_data.drop(columns=['Whole weight.1'])\n",
    "test_data = test_data.drop(columns=['Whole weight.1'])\n",
    "\n",
    "# Encode categorical feature 'Sex'\n",
    "le = LabelEncoder()\n",
    "train_data['Sex'] = le.fit_transform(train_data['Sex'])\n",
    "test_data['Sex'] = le.transform(test_data['Sex'])\n",
    "\n",
    "# Separate features and target in training data\n",
    "X = train_data.drop(columns=['id', 'Rings'])\n",
    "y = train_data['Rings']\n",
    "\n",
    "# Split data for model validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model 1: Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred_val_ridge = ridge_model.predict(X_val)\n",
    "rmsle_ridge = np.sqrt(mean_squared_log_error(y_val, np.maximum(0, y_pred_val_ridge)))\n",
    "\n",
    "print(\"RMSLE (Ridge Model):\", rmsle_ridge)\n",
    "\n",
    "# Model 2: Principal Component Regression (PCR)\n",
    "pca_pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=5)),  # Using 5 principal components\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit and predict with PCA model\n",
    "pca_pipeline.fit(X_train, y_train)\n",
    "y_pred_val_pca = pca_pipeline.predict(X_val)\n",
    "rmsle_pca = np.sqrt(mean_squared_log_error(y_val, np.maximum(0, y_pred_val_pca)))\n",
    "\n",
    "print(\"RMSLE (PCR Model):\", rmsle_pca)\n",
    "\n",
    "# Predictions on Test Data\n",
    "ridge_predictions = ridge_model.predict(test_data.drop(columns=['id']))\n",
    "pca_predictions = pca_pipeline.predict(test_data.drop(columns=['id']))\n",
    "\n",
    "# Create submission files\n",
    "submission_ridge = pd.DataFrame({'id': test_data['id'], 'Rings': np.maximum(0, ridge_predictions).round().astype(int)})\n",
    "submission_pca = pd.DataFrame({'id': test_data['id'], 'Rings': np.maximum(0, pca_predictions).round().astype(int)})\n",
    "\n",
    "# Save submission files\n",
    "submission_ridge.to_csv('C:/Users/arman/Downloads/ridge_submission.csv', index=False)\n",
    "submission_pca.to_csv('C:/Users/arman/Downloads/pca_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cceb0d0-b0ce-443b-9896-2be944be093f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
